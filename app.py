# app.py â€” å˜ä¸€ãƒ•ã‚¡ã‚¤ãƒ«ç‰ˆ CMMS ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ï¼ˆCSVå–è¾¼ã¤ãï¼‰
import os, io, textwrap, pandas as pd, duckdb as ddb
import streamlit as st
import plotly.express as px

st.set_page_config(page_title="CMMS ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ï¼ˆÎ²ï¼‰", layout="wide", page_icon="ğŸ› ï¸")

# ---- DB åˆæœŸåŒ– -----------------------------------------------------------
DB_PATH = os.environ.get("CMMS_DUCKDB_PATH", "app.duckdb")
os.makedirs(os.path.dirname(DB_PATH) or ".", exist_ok=True)
con = ddb.connect(DB_PATH)
con.execute("""
CREATE TABLE IF NOT EXISTS buildings(tenant TEXT, id TEXT, name TEXT, PRIMARY KEY(tenant,id));
CREATE TABLE IF NOT EXISTS locations(tenant TEXT, id TEXT, building_id TEXT, name TEXT, PRIMARY KEY(tenant,id));
CREATE TABLE IF NOT EXISTS floors(tenant TEXT, id TEXT, location_id TEXT, name TEXT, PRIMARY KEY(tenant,id));
CREATE TABLE IF NOT EXISTS rooms(tenant TEXT, id TEXT, floor_id TEXT, name TEXT, PRIMARY KEY(tenant,id));
CREATE TABLE IF NOT EXISTS devices(tenant TEXT, id TEXT, building_id TEXT, location_id TEXT, floor_id TEXT, room_id TEXT,
  name TEXT, category_l TEXT, category_m TEXT, category_s TEXT, symbol TEXT, cmms_url_rule TEXT,
  PRIMARY KEY(tenant,id));
CREATE TABLE IF NOT EXISTS targets(tenant TEXT, id TEXT, device_id TEXT, name TEXT, input_type TEXT,
  unit TEXT, lower DOUBLE, upper DOUBLE, ord INT, PRIMARY KEY(tenant,id));
CREATE TABLE IF NOT EXISTS schedules(tenant TEXT, id TEXT, job_id TEXT, name TEXT, freq TEXT, PRIMARY KEY(tenant,id));
CREATE TABLE IF NOT EXISTS schedule_targets(tenant TEXT, schedule_id TEXT, target_id TEXT,
  PRIMARY KEY(tenant,schedule_id,target_id));
CREATE TABLE IF NOT EXISTS schedule_dates(tenant TEXT, schedule_id TEXT, date DATE, status TEXT,
  done INT, total INT, done_at TIMESTAMP, PRIMARY KEY(tenant,schedule_id,date));
CREATE TABLE IF NOT EXISTS results(tenant TEXT, schedule_id TEXT, date DATE, target_id TEXT,
  value_num DOUBLE, value_text TEXT, value_bool BOOLEAN, judged TEXT,
  PRIMARY KEY(tenant,schedule_id,date,target_id));
CREATE TABLE IF NOT EXISTS issues(tenant TEXT, id TEXT, device_id TEXT, reported_on DATE, due_on DATE,
  status TEXT, severity TEXT, category TEXT, summary TEXT, cmms_url_rule TEXT, PRIMARY KEY(tenant,id));
CREATE TABLE IF NOT EXISTS documents(tenant TEXT, id TEXT, title TEXT, category TEXT, tags TEXT,
  url TEXT, version TEXT, ocr_status TEXT, ai_summary TEXT, ai_actions TEXT,
  uploaded_at TIMESTAMP DEFAULT now(), PRIMARY KEY(tenant,id));
CREATE TABLE IF NOT EXISTS document_bindings(tenant TEXT, doc_id TEXT, entity_type TEXT, entity_id TEXT,
  PRIMARY KEY(tenant,doc_id,entity_type,entity_id));
CREATE TABLE IF NOT EXISTS daily_kpis(tenant TEXT, date DATE, planned INT, done INT, overdue INT, findings INT,
  PRIMARY KEY(tenant,date));
""")

TENANT = st.session_state.setdefault("tenant", "demo")

# ---- å…±é€š: ç°¡æ˜“ã‚¢ãƒƒãƒ—ã‚µãƒ¼ãƒˆ ---------------------------------------------
def upsert_df(table: str, df: pd.DataFrame, pk: list[str]):
    if df.empty: return
    df = df.copy()
    df["tenant"] = TENANT
    cols = list(df.columns)
    for _, r in df.iterrows():
        where = " AND ".join([f"{k} = ?" for k in ["tenant", *pk]])
        con.execute(f"DELETE FROM {table} WHERE {where}", [TENANT, *[r[k] for k in pk]])
        con.execute(f"INSERT INTO {table}({','.join(cols)}) VALUES ({','.join(['?']*len(cols))})", r.tolist())

# ---- å–è¾¼ï¼šãƒã‚¹ã‚¿ï¼ˆéšå±¤ + è¨­å‚™ + target + schedule ç´ä»˜ã‘ï¼‰ ------------
def import_master(df: pd.DataFrame):
    df = df.rename(columns=str.lower)
    need = ["building_name","location_name","room_name","device_name","target_id","target_name","target_type_id","schedule_id"]
    missing = [c for c in need if c not in df.columns]
    if missing: st.error(f"å¿…é ˆåˆ—ãŒä¸è¶³: {missing}"); return
    df["floor_name"] = df.get("floor_name","æŒ‡å®šãªã—")
    # IDsï¼ˆåå‰ã‚’ãã®ã¾ã¾IDæ‰±ã„ã§OKï¼‰
    b = df[["building_name"]].drop_duplicates().rename(columns={"building_name":"name"}); b["id"]=b["name"]; upsert_df("buildings", b[["id","name"]], ["id"])
    l = df[["location_name","building_name"]].drop_duplicates().rename(columns={"location_name":"name","building_name":"building_id"})
    l["id"]=l["name"]; upsert_df("locations", l[["id","building_id","name"]], ["id"])
    f = df[["floor_name","location_name"]].drop_duplicates().rename(columns={"floor_name":"name","location_name":"location_id"})
    f["id"]=f["name"]; upsert_df("floors", f[["id","location_id","name"]], ["id"])
    r = df[["room_name","floor_name"]].drop_duplicates().rename(columns={"room_name":"name","floor_name":"floor_id"})
    r["id"]=r["name"]; upsert_df("rooms", r[["id","floor_id","name"]], ["id"])
    d = df[["device_name","building_name","location_name","floor_name","room_name"]].drop_duplicates().rename(
        columns={"device_name":"name","building_name":"building_id","location_name":"location_id","floor_name":"floor_id","room_name":"room_id"})
    d["id"]=d["name"]; d["category_l"]=d["category_m"]=d["category_s"]=d["symbol"]=d["cmms_url_rule"]=None
    upsert_df("devices", d[["id","building_id","location_id","floor_id","room_id","name","category_l","category_m","category_s","symbol","cmms_url_rule"]], ["id"])
    t = df[["target_id","device_name","target_name","target_type_id","unit","lower","upper","order_no"]].copy()
    t.rename(columns={"target_id":"id","device_name":"device_id","target_name":"name","target_type_id":"input_type","order_no":"ord"}, inplace=True)
    upsert_df("targets", t[["id","device_id","name","input_type","unit","lower","upper","ord"]], ["id"])
    s = df[["schedule_id"]].drop_duplicates().rename(columns={"schedule_id":"id"}); s["job_id"]=None; s["name"]=None; s["freq"]=None
    upsert_df("schedules", s[["id","job_id","name","freq"]], ["id"])
    stgt = df[["schedule_id","target_id"]].drop_duplicates().rename(columns={"schedule_id":"schedule_id","target_id":"target_id"})
    upsert_df("schedule_targets", stgt, ["schedule_id","target_id"])
    st.success(f"ãƒã‚¹ã‚¿å–è¾¼: {len(df)} è¡Œ")

# ---- å–è¾¼ï¼šé‹ç”¨ãƒã‚±ãƒƒãƒˆï¼ˆå®Ÿæ–½æ—¥ãƒ»é€²æ—ï¼‰ ---------------------------------
def import_tickets(df: pd.DataFrame):
    df = df.rename(columns=str.lower)
    need = ["date","schedule_id","status"]; miss=[c for c in need if c not in df.columns]
    if miss: st.error(f"å¿…é ˆåˆ—ãŒä¸è¶³: {miss}"); return
    def split_prog(x):
        try: a,b = str(x).split("/"); return int(a), int(b)
        except: return None, None
    prog = df.get("progress")
    done, total = zip(*[split_prog(x) for x in (prog if prog is not None else [])]) if len(df)>0 else ([],[])
    s = pd.DataFrame({
        "schedule_id": df["schedule_id"],
        "date": pd.to_datetime(df["date"]).dt.date,
        "status": df["status"],
        "done": done, "total": total,
        "done_at": pd.to_datetime(df.get("done_at"), errors="coerce")
    })
    upsert_df("schedule_dates", s, ["schedule_id","date"])
    st.success(f"ãƒã‚±ãƒƒãƒˆå–è¾¼: {len(df)} è¡Œ")

# ---- å–è¾¼ï¼šä¸å…·åˆ --------------------------------------------------------
def import_issues(df: pd.DataFrame):
    df = df.rename(columns=str.lower)
    need = ["id","reported_on"]; miss=[c for c in need if c not in df.columns]
    if miss: st.error(f"å¿…é ˆåˆ—ãŒä¸è¶³: {miss}"); return
    df["reported_on"] = pd.to_datetime(df["reported_on"], errors="coerce").dt.date
    if "due_on" in df.columns: df["due_on"] = pd.to_datetime(df["due_on"], errors="coerce").dt.date
    keep = ["id","device_id","reported_on","due_on","status","severity","category","summary","cmms_url_rule"]
    for k in keep:
        if k not in df.columns: df[k]=None
    upsert_df("issues", df[keep], ["id"])
    st.success(f"ä¸å…·åˆå–è¾¼: {len(df)} è¡Œ")

# ---- å–è¾¼ï¼šç‚¹æ¤œçµæœï¼ˆæ¨ªæŒã¡â†’ç¸¦meltï¼‰ -----------------------------------
def import_results_wide(df: pd.DataFrame):
    df = df.rename(columns=str.lower)
    fixed = ["schedule_id","device_id","target_id","target_name","target_type_id","unit"]
    date_cols = [c for c in df.columns if c not in fixed]
    rows = []
    for _, r in df.iterrows():
        for dc in date_cols:
            val = r[dc]
            if pd.isna(val) or str(val)=="":
                continue
            rows.append({
                "schedule_id": r["schedule_id"],
                "date": pd.to_datetime(dc).date(),
                "target_id": r["target_id"],
                "value_num": pd.to_numeric(val, errors="coerce"),
                "value_text": None if pd.to_numeric(val, errors="coerce")==pd.to_numeric(val, errors="coerce") else str(val),
                "value_bool": None,
                "judged": None
            })
    if rows:
        upsert_df("results", pd.DataFrame(rows), ["schedule_id","date","target_id"])
    st.success(f"ç‚¹æ¤œçµæœå–è¾¼: {len(df)} è¡Œï¼ˆç©ºå€¤ã¯é™¤å¤–ï¼‰")

# ---- KPI å†è¨ˆç®—ï¼ˆè¶…ç°¡æ˜“ï¼‰ ------------------------------------------------
def recalc_daily_kpis():
    con.execute("DELETE FROM daily_kpis WHERE tenant = ?", [TENANT])
    con.execute("""
        INSERT INTO daily_kpis
        SELECT ?, sd.date,
               COUNT(*) AS planned,
               SUM(CASE WHEN COALESCE(status,'') IN ('å®Œäº†','å®Ÿæ–½æ¸ˆ') THEN 1 ELSE 0 END) AS done,
               SUM(CASE WHEN sd.date < today() AND COALESCE(status,'') NOT IN ('å®Œäº†','å®Ÿæ–½æ¸ˆ') THEN 1 ELSE 0 END) AS overdue,
               0 AS findings
        FROM schedule_dates sd WHERE tenant=? GROUP BY sd.date
    """, [TENANT, TENANT])

# ========================= UI =============================================
st.title("CMMS ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ï¼ˆÎ²ï¼‰")
tab1, tab2, tab3, tab4, tab5, tab6 = st.tabs(["ğŸ“… æ—¥å ±","ğŸ› ï¸ è¨­å‚™","ğŸ“ˆ æœˆå ±","ğŸ“„ ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ","ğŸ“¥ å–è¾¼","ğŸ¤– AIÎ²"])

with tab5:  # å–è¾¼
    st.subheader("CSV å–è¾¼")
    f1 = st.file_uploader("ãƒã‚¹ã‚¿ï¼ˆéšå±¤+è¨­å‚™+target+scheduleï¼‰CSV", type=["csv"])
    if f1: import_master(pd.read_csv(f1))
    f2 = st.file_uploader("operation_tickets.csvï¼ˆå®Ÿæ–½æ—¥/é€²æ—ï¼‰", type=["csv"])
    if f2: import_tickets(pd.read_csv(f2))
    f3 = st.file_uploader("issues.csvï¼ˆä¸å…·åˆï¼‰", type=["csv"])
    if f3: import_issues(pd.read_csv(f3))
    f4 = st.file_uploader("ç‚¹æ¤œçµæœï¼ˆæ¨ªæŒã¡ï¼‰CSV", type=["csv"])
    if f4: import_results_wide(pd.read_csv(f4))
    if st.button("KPIå†è¨ˆç®—"): recalc_daily_kpis(); st.success("daily_kpis å†è¨ˆç®—")

with tab1:  # æ—¥å ±
    st.subheader("æœ¬æ—¥ã®æ¥­å‹™äºˆå®šã¨é€²æ—")
    target_date = st.date_input("å¯¾è±¡æ—¥", pd.Timestamp.today()).to_pydatetime().date()
    kpi = con.execute("SELECT planned, done, overdue FROM daily_kpis WHERE tenant=? AND date=?",
                      [TENANT, target_date]).fetchone()
    planned, done, overdue = (kpi if kpi else (0,0,0))
    c1,c2,c3 = st.columns(3); c1.metric("äºˆå®š", planned); c2.metric("å®Œäº†", done); c3.metric("æœŸé™è¶…é", overdue)
    df = con.execute("SELECT * FROM schedule_dates WHERE tenant=? AND date=?", [TENANT, target_date]).df()
    st.dataframe(df, use_container_width=True)

    st.subheader("æœ¬æ—¥ç™ºç”Ÿã®ä¸å…·åˆ")
    issues = con.execute("SELECT * FROM issues WHERE tenant=? AND reported_on=?", [TENANT, target_date]).df()
    st.dataframe(issues, use_container_width=True)

with tab2:  # è¨­å‚™
    st.subheader("è¨­å‚™ã®ç‚¹æ¤œçµæœ")
    devices = con.execute("SELECT id, name FROM devices WHERE tenant=?", [TENANT]).df()
    dev = st.selectbox("è¨­å‚™ã‚’é¸æŠ", options=devices["id"] if not devices.empty else [])
    dr = st.date_input("æœŸé–“", [])
    if dev and len(dr)==2:
        q = """
        SELECT r.date, r.target_id, r.value_num, r.value_text
        FROM results r JOIN targets t ON t.tenant=r.tenant AND t.id=r.target_id
        WHERE r.tenant=? AND t.device_id=? AND r.date BETWEEN ? AND ? ORDER BY r.date
        """
        df = con.execute(q, [TENANT, dev, dr[0], dr[1]]).df()
        num = df.dropna(subset=["value_num"])
        if not num.empty:
            st.plotly_chart(px.line(num, x="date", y="value_num", color="target_id"), use_container_width=True)
        qual = df[df["value_num"].isna()]
        if not qual.empty:
            st.dataframe(qual.pivot_table(index="date", columns="target_id", values="value_text", aggfunc="first"),
                         use_container_width=True)

with tab3:  # æœˆå ±ï¼ˆãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ï¼‰
    st.subheader("æŒ‡å®šæœˆã®ã‚µãƒãƒªãƒ¼ï¼ˆãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ï¼‰")
    st.info("CSVå–è¾¼å¾Œã€æœˆæ¬¡é›†è¨ˆã‚’å®Ÿè£…ã—ã¾ã™ã€‚")

with tab4:  # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆï¼ˆãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ï¼‰
    st.subheader("ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆä¸€è¦§ï¼ˆãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ï¼‰")
    docs = con.execute("SELECT id,title,category,tags,ai_summary FROM documents WHERE tenant=?", [TENANT]).df()
    st.dataframe(docs, use_container_width=True)

with tab6:  # AIï¼ˆãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ï¼‰
    st.subheader("AIã‚µãƒãƒªãƒ¼ï¼ˆÎ²ï¼‰")
    st.info("OCR/AIé€£æºã¯å¾Œã§æ¥ç¶šã€‚ã¾ãšã¯CSVâ†’ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã®æµã‚Œã‚’å›ºã‚ã¾ã™ã€‚")

st.caption("Theme: ç®¡ç†ãƒ­ã‚¤ãƒ‰é¢¨ / ãƒ‡ãƒ¼ã‚¿ã¯ UTF-8 CSV ã‚’ å–è¾¼ã‚¿ãƒ–ã‹ã‚‰æŠ•å…¥")
