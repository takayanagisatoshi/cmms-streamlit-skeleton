# app.py â€” å˜ä¸€ãƒ•ã‚¡ã‚¤ãƒ«ç‰ˆ CMMS ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ï¼ˆCSVå–è¾¼ã¤ãï¼‰
import os, io, textwrap, re
from datetime import date
import pandas as pd
import duckdb as ddb
import streamlit as st
import plotly.express as px
import numpy as np
from plotly.subplots import make_subplots
import plotly.graph_objects as go

st.set_page_config(page_title="CMMS ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ï¼ˆÎ²ï¼‰", layout="wide", page_icon="ğŸ› ï¸")

# ---- DB åˆæœŸåŒ– -----------------------------------------------------------
DB_PATH = os.environ.get("CMMS_DUCKDB_PATH", "app.duckdb")
os.makedirs(os.path.dirname(DB_PATH) or ".", exist_ok=True)
con = ddb.connect(DB_PATH)
con.execute("""
CREATE TABLE IF NOT EXISTS buildings(tenant TEXT, id TEXT, name TEXT, PRIMARY KEY(tenant,id));
CREATE TABLE IF NOT EXISTS locations(tenant TEXT, id TEXT, building_id TEXT, name TEXT, PRIMARY KEY(tenant,id));
CREATE TABLE IF NOT EXISTS floors(tenant TEXT, id TEXT, location_id TEXT, name TEXT, PRIMARY KEY(tenant,id));
CREATE TABLE IF NOT EXISTS rooms(tenant TEXT, id TEXT, floor_id TEXT, name TEXT, PRIMARY KEY(tenant,id));
CREATE TABLE IF NOT EXISTS devices(tenant TEXT, id TEXT, building_id TEXT, location_id TEXT, floor_id TEXT, room_id TEXT,
  name TEXT, category_l TEXT, category_m TEXT, category_s TEXT, symbol TEXT, cmms_url_rule TEXT,
  PRIMARY KEY(tenant,id));
CREATE TABLE IF NOT EXISTS targets(tenant TEXT, id TEXT, device_id TEXT, name TEXT, input_type TEXT,
  unit TEXT, lower DOUBLE, upper DOUBLE, ord INT, PRIMARY KEY(tenant,id));
CREATE TABLE IF NOT EXISTS schedules(tenant TEXT, id TEXT, job_id TEXT, name TEXT, freq TEXT, PRIMARY KEY(tenant,id));
CREATE TABLE IF NOT EXISTS schedule_targets(tenant TEXT, schedule_id TEXT, target_id TEXT,
  PRIMARY KEY(tenant,schedule_id,target_id));
CREATE TABLE IF NOT EXISTS schedule_dates(tenant TEXT, schedule_id TEXT, date DATE, status TEXT,
  done INT, total INT, done_at TIMESTAMP, PRIMARY KEY(tenant,schedule_id,date));
CREATE TABLE IF NOT EXISTS results(tenant TEXT, schedule_id TEXT, date DATE, target_id TEXT,
  value_num DOUBLE, value_text TEXT, value_bool BOOLEAN, judged TEXT,
  PRIMARY KEY(tenant,schedule_id,date,target_id));
CREATE TABLE IF NOT EXISTS issues(tenant TEXT, id TEXT, device_id TEXT, reported_on DATE, due_on DATE,
  status TEXT, severity TEXT, category TEXT, summary TEXT, cmms_url_rule TEXT, PRIMARY KEY(tenant,id));
CREATE TABLE IF NOT EXISTS documents(tenant TEXT, id TEXT, title TEXT, category TEXT, tags TEXT,
  url TEXT, version TEXT, ocr_status TEXT, ai_summary TEXT, ai_actions TEXT,
  uploaded_at TIMESTAMP DEFAULT now(), PRIMARY KEY(tenant,id));
CREATE TABLE IF NOT EXISTS document_bindings(tenant TEXT, doc_id TEXT, entity_type TEXT, entity_id TEXT,
  PRIMARY KEY(tenant,doc_id,entity_type,entity_id));
CREATE TABLE IF NOT EXISTS daily_kpis(tenant TEXT, date DATE, planned INT, done INT, overdue INT, findings INT,
  PRIMARY KEY(tenant,date));
""")

TENANT = st.session_state.setdefault("tenant", "demo")

# ---- å…±é€š: ç°¡æ˜“ã‚¢ãƒƒãƒ—ã‚µãƒ¼ãƒˆ ---------------------------------------------
def upsert_df(table: str, df: pd.DataFrame, pk: list[str]):
    if df is None or df.empty:
        return
    df = df.copy()
    df["tenant"] = TENANT
    cols = list(df.columns)
    for _, r in df.iterrows():
        where = " AND ".join([f"{k} = ?" for k in ["tenant", *pk]])
        con.execute(f"DELETE FROM {table} WHERE {where}", [TENANT, *[r[k] for k in pk]])
        con.execute(f"INSERT INTO {table}({','.join(cols)}) VALUES ({','.join(['?']*len(cols))})", r.tolist())

# ---- ä¾¿åˆ©ï¼šéšå±¤ãƒ‘ã‚¹ã§ä¸€æ„ãª device_id ã‚’ä½œã‚‹ ----------------------------
def _dev_id(b, l, f, r, name):
    b = b or "æŒ‡å®šãªã—"; l = l or "æŒ‡å®šãªã—"; f = f or "æŒ‡å®šãªã—"; r = r or "æŒ‡å®šãªã—"; name = name or "ä¸æ˜è¨­å‚™"
    return f"{b}|{l}|{f}|{r}|{name}"

# ---- å–è¾¼ï¼šãƒã‚¹ã‚¿ï¼ˆéšå±¤ + è¨­å‚™ + target + schedule ç´ä»˜ã‘ï¼‰ ------------
def import_master(df: pd.DataFrame):
    df = df.rename(columns=str.lower)
    need = ["building_name","location_name","room_name","device_name","target_id","target_name","target_type_id","schedule_id"]
    miss = [c for c in need if c not in df.columns]
    if miss:
        st.error(f"å¿…é ˆåˆ—ãŒä¸è¶³: {miss}"); return
    if "floor_name" not in df.columns:
        df["floor_name"] = "æŒ‡å®šãªã—"

    # buildings
    b = df[["building_name"]].drop_duplicates().rename(columns={"building_name":"id"})
    b["name"] = b["id"]
    upsert_df("buildings", b[["id","name"]], ["id"])

    # locations
    l = df[["building_name","location_name"]].drop_duplicates().rename(
        columns={"building_name":"building_id","location_name":"id"})
    l["name"] = l["id"]
    upsert_df("locations", l[["id","building_id","name"]], ["id"])

    # floors
    f = df[["location_name","floor_name"]].drop_duplicates().rename(
        columns={"location_name":"location_id","floor_name":"id"})
    f["name"] = f["id"]
    upsert_df("floors", f[["id","location_id","name"]], ["id"])

    # rooms
    r = df[["floor_name","room_name"]].drop_duplicates().rename(
        columns={"floor_name":"floor_id","room_name":"id"})
    r["name"] = r["id"]
    upsert_df("rooms", r[["id","floor_id","name"]], ["id"])

    # devicesï¼ˆéšå±¤ãƒ‘ã‚¹IDï¼‰
    d = df[["building_name","location_name","floor_name","room_name","device_name"]].drop_duplicates()
    d = d.rename(columns={"building_name":"building_id","location_name":"location_id","floor_name":"floor_id",
                          "room_name":"room_id","device_name":"name"})
    d["id"] = d.apply(lambda x: _dev_id(x["building_id"],x["location_id"],x["floor_id"],x["room_id"],x["name"]), axis=1)
    d["category_l"]=d["category_m"]=d["category_s"]=d["symbol"]=d["cmms_url_rule"]=None
    upsert_df("devices", d[["id","building_id","location_id","floor_id","room_id","name",
                            "category_l","category_m","category_s","symbol","cmms_url_rule"]], ["id"])

    # targetsï¼ˆdevice_id ã‚’ãƒ‘ã‚¹IDã«ã™ã‚‹ï¼‰
    t = df[["building_name","location_name","floor_name","room_name","device_name","target_id",
            "target_name","target_type_id","unit","lower","upper","order_no"]].copy()
    t["device_id"] = t.apply(lambda x: _dev_id(x["building_name"],x["location_name"],x["floor_name"],x["room_name"],x["device_name"]), axis=1)
    t = t.rename(columns={"target_id":"id","target_name":"name","target_type_id":"input_type","order_no":"ord"})
    upsert_df("targets", t[["id","device_id","name","input_type","unit","lower","upper","ord"]].drop_duplicates(), ["id"])

    # schedules
    s = df[["schedule_id"]].drop_duplicates().rename(columns={"schedule_id":"id"})
    s["job_id"]=None; s["name"]=None; s["freq"]=None
    upsert_df("schedules", s[["id","job_id","name","freq"]], ["id"])

    # schedule_targets
    stgt = df[["schedule_id","target_id"]].drop_duplicates().rename(columns={"schedule_id":"schedule_id","target_id":"target_id"})
    upsert_df("schedule_targets", stgt, ["schedule_id","target_id"])

    st.success(f"ãƒã‚¹ã‚¿å–è¾¼: {len(df)} è¡Œï¼ˆè¨­å‚™/ã‚¿ãƒ¼ã‚²ãƒƒãƒˆ/ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ç´ä»˜ã‘ï¼‰")

# ---- å–è¾¼ï¼šé‹ç”¨ãƒã‚±ãƒƒãƒˆï¼ˆå®Ÿæ–½æ—¥ãƒ»é€²æ—ï¼‰ ---------------------------------
def import_tickets(df: pd.DataFrame):
    df = df.rename(columns=str.lower)
    need = ["date","schedule_id","status"]; miss=[c for c in need if c not in df.columns]
    if miss: st.error(f"å¿…é ˆåˆ—ãŒä¸è¶³: {miss}"); return

    def split_prog(x):
        try: a,b = str(x).split("/"); return int(a), int(b)
        except: return None, None

    prog = df.get("progress")
    done, total = zip(*[split_prog(x) for x in (prog if prog is not None else [])]) if len(df)>0 else ([],[])
    s = pd.DataFrame({
        "schedule_id": df["schedule_id"],
        "date": pd.to_datetime(df["date"], errors="coerce").dt.date,
        "status": df["status"],
        "done": done, "total": total,
        "done_at": pd.to_datetime(df.get("done_at"), errors="coerce")
    })
    s = s.dropna(subset=["date"])
    upsert_df("schedule_dates", s, ["schedule_id","date"])
    st.success(f"ãƒã‚±ãƒƒãƒˆå–è¾¼: {len(s)} è¡Œ")

# ---- å–è¾¼ï¼šä¸å…·åˆï¼ˆéšå±¤ãƒ’ãƒ³ãƒˆã§ device_id è‡ªå‹•è§£æ±ºï¼‰ --------------------
def import_issues(df: pd.DataFrame):
    df = df.rename(columns=str.lower)

    # reported_on / due_on ã®åˆ¥åã«å¯¾å¿œ
    if "reported_on" not in df.columns and "ç™ºç”Ÿæ—¥æ™‚" in df.columns:
        df.rename(columns={"ç™ºç”Ÿæ—¥æ™‚":"reported_on"}, inplace=True)
    if "due_on" not in df.columns and "å¯¾å¿œæœŸé™" in df.columns:
        df.rename(columns={"å¯¾å¿œæœŸé™":"due_on"}, inplace=True)

    # è¨­å‚™åãªã©ã®ãƒ’ãƒ³ãƒˆåˆ—ã‚’å–ã‚Šè¾¼ã‚€
    if "è¨­å‚™" in df.columns and "device_id" not in df.columns:
        df["_equip_hint"] = df["è¨­å‚™"]
    elif "device" in df.columns and "device_id" not in df.columns:
        df["_equip_hint"] = df["device"]
    elif "equipment" in df.columns and "device_id" not in df.columns:
        df["_equip_hint"] = df["equipment"]

    for col in [("éƒ¨å±‹å","_room_hint"),("room_name","_room_hint"),
                ("ãƒ•ãƒ­ã‚¢","_floor_hint"),("floor_name","_floor_hint"),
                ("æ£Ÿ","_loc_hint"),("location_name","_loc_hint"),
                ("ç‰©ä»¶","_bld_hint"),("building_name","_bld_hint")]:
        if col[0] in df.columns: df[col[1]] = df[col[0]]

    # devices ä¸€è¦§ï¼ˆéšå±¤åˆ—ã‚ã‚Šï¼‰
    devs = con.execute("SELECT id,name,building_id,location_id,floor_id,room_id FROM devices WHERE tenant=?",
                       [TENANT]).df()

    def resolve_device(row):
        cand = devs.copy()
        if pd.notna(row.get("_equip_hint")): cand = cand[cand["name"]==row["_equip_hint"]]
        if pd.notna(row.get("_room_hint")):  cand = cand[cand["room_id"]==row["_room_hint"]]
        if pd.notna(row.get("_floor_hint")): cand = cand[cand["floor_id"]==row["_floor_hint"]]
        if pd.notna(row.get("_loc_hint")):   cand = cand[cand["location_id"]==row["_loc_hint"]]
        if pd.notna(row.get("_bld_hint")):   cand = cand[cand["building_id"]==row["_bld_hint"]]
        if len(cand)==1:
            return cand.iloc[0]["id"]
        cand2 = devs[devs["name"]==row.get("_equip_hint")]
        return cand2.iloc[0]["id"] if len(cand2)==1 else None

    if "device_id" not in df.columns:
        df["device_id"] = df.apply(resolve_device, axis=1)

    # æ­£è¦åŒ–ã—ã¦ä¿å­˜
    df["reported_on"] = pd.to_datetime(df.get("reported_on"), errors="coerce").dt.date
    if "due_on" in df.columns: df["due_on"] = pd.to_datetime(df["due_on"], errors="coerce").dt.date
    keep = ["id","device_id","reported_on","due_on","status","severity","category","summary","cmms_url_rule"]
    for k in keep:
        if k not in df.columns: df[k]=None
    out = df[keep].dropna(subset=["id","reported_on"])
    upsert_df("issues", out, ["id"])
    st.success(f"ä¸å…·åˆå–è¾¼: {len(out)} è¡Œï¼ˆdevice_idè‡ªå‹•è§£æ±º {out['device_id'].notna().sum()}ä»¶ï¼‰")

# ---- å–è¾¼ï¼šç‚¹æ¤œçµæœï¼ˆæ¨ªæŒã¡â†’ç¸¦meltï¼‰ -----------------------------------
def import_results_wide(df: pd.DataFrame):
    df = df.rename(columns=lambda c: str(c).strip())
    df = df.rename(columns=str.lower)

    # ãƒ˜ãƒƒãƒ€ãƒ¼ãŒæ—¥ä»˜å½¢å¼ã®ã‚‚ã®ã ã‘ï¼ˆYYYY-MM-DD / YYYY/MM/DDï¼‰
    date_cols = [c for c in df.columns
                 if re.fullmatch(r"\d{4}[-/]\d{2}[-/]\d{2}", c)
                 or re.fullmatch(r"\d{4}/\d{2}/\d{2}", c)]

    rows = []
    for _, r in df.iterrows():
        for dc in date_cols:
            val = r.get(dc)
            if pd.isna(val) or str(val) == "":
                continue
            d = pd.to_datetime(dc.replace("/", "-"), errors="coerce")
            if pd.isna(d):
                continue
            num = pd.to_numeric(val, errors="coerce")
            rows.append({
                "schedule_id": r.get("schedule_id"),
                "date": d.date(),
                "target_id": r.get("target_id"),
                "value_num": None if pd.isna(num) else float(num),
                "value_text": None if not pd.isna(num) else str(val),
                "value_bool": None,
                "judged": None
            })

    out = pd.DataFrame(rows)
    out = out.dropna(subset=["schedule_id","target_id","date"])
    if not out.empty:
        upsert_df("results", out, ["schedule_id","date","target_id"])
    st.success(f"ç‚¹æ¤œçµæœå–è¾¼: {len(df)} è¡Œï¼ˆ{len(date_cols)}æœ¬ã®æ—¥ä»˜åˆ—ã‚’å‡¦ç†ã€ãƒ¬ã‚³ãƒ¼ãƒ‰{len(out)}ä»¶ï¼‰")

# ---- KPI å†è¨ˆç®—ï¼ˆè¶…ç°¡æ˜“ï¼‰ ------------------------------------------------
def recalc_daily_kpis():
    con.execute("DELETE FROM daily_kpis WHERE tenant = ?", [TENANT])
    con.execute("""
        INSERT INTO daily_kpis
        SELECT ?, sd.date,
               COUNT(*) AS planned,
               SUM(CASE WHEN COALESCE(status,'') IN ('å®Œäº†','å®Ÿæ–½æ¸ˆ') THEN 1 ELSE 0 END) AS done,
               SUM(CASE WHEN sd.date < today() AND COALESCE(status,'') NOT IN ('å®Œäº†','å®Ÿæ–½æ¸ˆ') THEN 1 ELSE 0 END) AS overdue,
               0 AS findings
        FROM schedule_dates sd WHERE tenant=? GROUP BY sd.date
    """, [TENANT, TENANT])

# ========================= UI =============================================
st.title("CMMS ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ï¼ˆÎ²ï¼‰")
tab1, tab2, tab3, tab4, tab5, tab6 = st.tabs(["ğŸ“… æ—¥å ±","ğŸ› ï¸ è¨­å‚™","ğŸ“ˆ æœˆå ±","ğŸ“„ ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ","ğŸ“¥ å–è¾¼","ğŸ¤– AIÎ²"])

# å–è¾¼
with tab5:
    st.subheader("CSV å–è¾¼")
    f1 = st.file_uploader("ãƒã‚¹ã‚¿ï¼ˆéšå±¤+è¨­å‚™+target+scheduleï¼‰CSV", type=["csv"])
    if f1: import_master(pd.read_csv(f1))
    f2 = st.file_uploader("operation_tickets.csvï¼ˆå®Ÿæ–½æ—¥/é€²æ—ï¼‰", type=["csv"])
    if f2: import_tickets(pd.read_csv(f2))
    f3 = st.file_uploader("issues.csvï¼ˆä¸å…·åˆï¼‰", type=["csv"])
    if f3: import_issues(pd.read_csv(f3))
    f4 = st.file_uploader("ç‚¹æ¤œçµæœï¼ˆæ¨ªæŒã¡ï¼‰CSV", type=["csv"])
    if f4: import_results_wide(pd.read_csv(f4))
    if st.button("KPIå†è¨ˆç®—"): recalc_daily_kpis(); st.success("daily_kpis å†è¨ˆç®—")

# æ—¥å ±
with tab1:
    st.subheader("æœ¬æ—¥ã®æ¥­å‹™äºˆå®šã¨é€²æ—")
    target_date = st.date_input("å¯¾è±¡æ—¥", value=date.today())
    kpi = con.execute(
        "SELECT planned, done, overdue FROM daily_kpis WHERE tenant=? AND date=?",
        [TENANT, target_date]).fetchone()
    planned, done, overdue = (kpi if kpi else (0,0,0))
    c1,c2,c3 = st.columns(3); c1.metric("äºˆå®š", planned); c2.metric("å®Œäº†", done); c3.metric("æœŸé™è¶…é", overdue)
    df = con.execute("SELECT * FROM schedule_dates WHERE tenant=? AND date=?", [TENANT, target_date]).df()
    st.dataframe(df, use_container_width=True)

    st.subheader("æœ¬æ—¥ç™ºç”Ÿã®ä¸å…·åˆ")
    issues = con.execute("SELECT * FROM issues WHERE tenant=? AND reported_on=?", [TENANT, target_date]).df()
    st.dataframe(issues, use_container_width=True)

# è¨­å‚™
with tab2:
    st.title("ğŸ› ï¸ è¨­å‚™ãƒšãƒ¼ã‚¸")

    # æ®µéšé¸æŠï¼ˆç‰©ä»¶â†’æ£Ÿâ†’ãƒ•ãƒ­ã‚¢â†’éƒ¨å±‹â†’è¨­å‚™ï¼‰
    blds = con.execute("SELECT DISTINCT building_id FROM devices WHERE tenant=?", [TENANT]).df()["building_id"].tolist()
    if not blds:
        st.info("ã¾ãšã¯ã€ğŸ“¥ å–è¾¼ã€ã‹ã‚‰ãƒã‚¹ã‚¿CSVã‚’æŠ•å…¥ã—ã¦ãã ã•ã„ã€‚"); st.stop()
    bld = st.selectbox("ç‰©ä»¶", blds)

    locs = con.execute(
        "SELECT DISTINCT location_id FROM devices WHERE tenant=? AND building_id=?",
        [TENANT, bld]).df()["location_id"].tolist()
    loc = st.selectbox("æ£Ÿ", locs) if locs else None

    flrs = con.execute(
        "SELECT DISTINCT floor_id FROM devices WHERE tenant=? AND building_id=? AND location_id=?",
        [TENANT, bld, loc]).df()["floor_id"].tolist() if loc else []
    flr = st.selectbox("ãƒ•ãƒ­ã‚¢", flrs) if flrs else None

    rooms = con.execute(
        "SELECT DISTINCT room_id FROM devices WHERE tenant=? AND building_id=? AND location_id=? AND floor_id=?",
        [TENANT, bld, loc, flr]).df()["room_id"].tolist() if flr else []
    room = st.selectbox("éƒ¨å±‹", rooms) if rooms else None

    devs = con.execute(
        """SELECT id,name FROM devices
           WHERE tenant=? AND building_id=? AND location_id=? AND floor_id=? AND room_id=?""",
        [TENANT, bld, loc, flr, room]).df() if room else pd.DataFrame(columns=["id","name"])
    dev = st.selectbox("è¨­å‚™", options=devs["id"] if not devs.empty else [])
    if not dev:
        st.stop()

    meta = con.execute("SELECT * FROM devices WHERE tenant=? AND id=?", [TENANT, dev]).df().iloc[0]
    st.markdown(f"### {meta['name']}ã€€ã€”{bld} / {loc} / {flr} / {room}ã€•")
    if pd.notna(meta.get("cmms_url_rule")) and str(meta.get("cmms_url_rule")) not in ("", "None"):
        st.link_button("CMMSã§é–‹ã", str(meta["cmms_url_rule"]))

    # æœŸé–“
    dr = st.date_input("æœŸé–“", [])
    if len(dr) != 2:
        st.info("æœŸé–“ã‚’é¸æŠã™ã‚‹ã¨ã€ã‚°ãƒ©ãƒ•ã¨è¡¨ãŒè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚"); st.stop()

    # ç‚¹æ¤œçµæœï¼ˆtargets ã¨é–¾å€¤ã‚’ JOINï¼‰
    q = """
      SELECT r.date, r.target_id, r.value_num, r.value_text,
             t.name AS target_name, t.unit, t.lower, t.upper
      FROM results r
      JOIN targets t ON t.tenant=r.tenant AND t.id=r.target_id
      WHERE r.tenant=? AND t.device_id=? AND r.date BETWEEN ? AND ?
      ORDER BY r.date
    """
    df = con.execute(q, [TENANT, dev, dr[0], dr[1]]).df()
    if df.empty:
        st.warning("æœŸé–“å†…ã®ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚"); st.stop()

    df["date"] = pd.to_datetime(df["date"])
    # ç•°å¸¸ï¼ˆé–¾å€¤é€¸è„± or Ã—/NGï¼‰
    abnormal_mask = (
        (df["value_num"].notna() & (
            (df["lower"].notna() & (df["value_num"] < df["lower"])) |
            (df["upper"].notna() & (df["value_num"] > df["upper"]))
        )) |
        (df["value_num"].isna() & df["value_text"].isin(["Ã—","NG"]))
    )
    c1, c2, c3 = st.columns(3)
    c1.metric("å¯¾è±¡é …ç›®", int(df["target_id"].nunique()))
    c2.metric("ãƒ‡ãƒ¼ã‚¿ç‚¹æ•°", int(df.shape[0]))
    c3.metric("ç•°å¸¸ä»¶æ•°", int(abnormal_mask.sum()))

    # äº”æ„Ÿã®ã‚¹ã‚³ã‚¢åŒ–
    label_to_score = {"â—‹":0, "OK":0, "è‰¯":0, "â–³":1, "è¦ç¢ºèª":1, "æ³¨æ„":1, "Ã—":2, "NG":2, "ç•°å¸¸":2}
    num  = df.dropna(subset=["value_num"]).copy()
    qual = df[df["value_num"].isna()].copy()
    qual["score"] = qual["value_text"].map(label_to_score).fillna(np.nan)

    # ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ç”¨ãƒ‡ãƒ¼ã‚¿
    if not qual.empty:
        heat = (qual.pivot_table(index="target_name", columns="date", values="score", aggfunc="max")
                .sort_index())
    else:
        heat = pd.DataFrame(index=[], columns=[])

    # åŒä¸€æ™‚é–“è»¸ã®è¤‡åˆå›³
    fig = make_subplots(rows=2, cols=1, shared_xaxes=True, vertical_spacing=0.02,
                        row_heights=[0.62, 0.38],
                        subplot_titles=("æ•°å€¤ã‚¿ãƒ¼ã‚²ãƒƒãƒˆï¼ˆæ¨ç§»ï¼‰", "äº”æ„Ÿ/é¸æŠã‚¿ãƒ¼ã‚²ãƒƒãƒˆï¼ˆ0=OK, 1=æ³¨æ„, 2=ç•°å¸¸ï¼‰"))
    # ä¸Šæ®µï¼šæ•°å€¤ãƒ©ã‚¤ãƒ³
    for name, g in num.groupby("target_name"):
        u = str(g["unit"].iloc[0] if "unit" in g else "")
        fig.add_trace(
            go.Scatter(x=g["date"], y=g["value_num"], mode="lines+markers",
                       name=str(name), hovertemplate="%{x|%Y-%m-%d}<br>%{y} "+u),
            row=1, col=1
        )
    # ç•°å¸¸æ—¥ã®ç¸¦å¸¯
    if not qual.empty:
        bad_days = qual[qual["score"] >= 2]["date"].dt.normalize().unique()
        for d in bad_days:
            fig.add_vrect(x0=d, x1=d, row="all", col=1, fillcolor="red", opacity=0.08, line_width=0)
    # ä¸‹æ®µï¼šäº”æ„Ÿãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—
    if not heat.empty:
        colorscale = [[0.0, "#3CB371"], [0.5, "#FFD166"], [1.0, "#EF476F"]]  # 0=ç·‘,1=é»„,2=èµ¤
        fig.add_trace(
            go.Heatmap(z=heat.values, x=heat.columns, y=heat.index,
                       zmin=0, zmax=2, colorscale=colorscale, colorbar=dict(title=""),
                       hovertemplate="%{y}<br>%{x|%Y-%m-%d}<br>çŠ¶æ…‹=%{z}<extra></extra>"),
            row=2, col=1
        )
    fig.update_layout(height=700, margin=dict(l=10,r=10,t=40,b=10))
    fig.update_xaxes(matches="x", row=1, col=1)
    st.plotly_chart(fig, use_container_width=True)

    # æ•°å€¤è¦ç´„è¡¨
    if not num.empty:
        latest = num.sort_values("date").groupby("target_name").tail(1).set_index("target_name")[["value_num","unit"]]
        stats = num.groupby("target_name")["value_num"].agg(æœ€å°="min", æœ€å¤§="max", å¹³å‡="mean")
        summary = latest.join(stats, how="left").rename(columns={"value_num":"æœ€æ–°å€¤"})
        st.markdown("**æ•°å€¤ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã®è¦ç´„**")
        st.dataframe(summary.reset_index(), use_container_width=True)

    # äº”æ„Ÿãƒ†ãƒ¼ãƒ–ãƒ«
    if not qual.empty:
        st.markdown("**äº”æ„Ÿ/é¸æŠã‚¿ãƒ¼ã‚²ãƒƒãƒˆï¼ˆè¡¨ï¼‰**")
        st.dataframe(
            qual.pivot_table(index="date", columns="target_name", values="value_text", aggfunc="first"),
            use_container_width=True
        )

    # ã“ã®è¨­å‚™ã®ä¸å…·åˆ
    st.subheader("ã“ã®è¨­å‚™ã«ç´ã¥ãä¸å…·åˆ")
    iss = con.execute(
        """SELECT id, reported_on, due_on, status, severity, category, summary
           FROM issues WHERE tenant=? AND device_id=?
           ORDER BY COALESCE(due_on, reported_on) DESC""",
        [TENANT, dev]).df()
    c1, c2, c3 = st.columns(3)
    if iss.empty:
        c1.metric("æœªå®Œäº†", 0); c2.metric("æœŸé™è¶…é", 0); c3.metric("ä»Šæœˆæ–°è¦", 0)
        st.info("ç´ã¥ãä¸å…·åˆã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
    else:
        not_done = ~iss["status"].isin(["å®Œäº†","å¯¾å¿œæ¸ˆ"])
        overdue = pd.to_datetime(iss["due_on"], errors="coerce") < pd.Timestamp.today()
        this_month = pd.to_datetime(iss["reported_on"], errors="coerce").dt.to_period("M") == pd.Timestamp.today().to_period("M")
        c1.metric("æœªå®Œäº†", int(iss[not_done].shape[0]))
        c2.metric("æœŸé™è¶…é", int(iss[not_done & overdue].shape[0]))
        c3.metric("ä»Šæœˆæ–°è¦", int(iss[this_month].shape[0]))
        st.dataframe(iss, use_container_width=True)

    # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ
    st.subheader("ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ")
    docs = con.execute(
        """SELECT d.id, d.title, d.category, d.tags, d.ai_summary
           FROM document_bindings b
           JOIN documents d ON d.tenant=b.tenant AND d.id=b.doc_id
           WHERE b.tenant=? AND b.entity_type='device' AND b.entity_id=?
           ORDER BY d.uploaded_at DESC""",
        [TENANT, dev]).df()
    if docs.empty:
        st.info("ã“ã®è¨­å‚™ã«ç´ã¥ããƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã¯æœªç™»éŒ²ã§ã™ã€‚")
    else:
        st.dataframe(docs, use_container_width=True)

    # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå®šç¾©
    st.subheader("ç‚¹æ¤œé …ç›®ï¼ˆTargets å®šç¾©ï¼‰")
    tl = con.execute(
        """SELECT id AS target_id, name, input_type, unit, lower, upper, ord
           FROM targets WHERE tenant=? AND device_id=? ORDER BY ord""",
        [TENANT, dev]).df()
    st.dataframe(tl, use_container_width=True)

# æœˆå ±ï¼ˆãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ï¼‰
with tab3:
    st.subheader("æŒ‡å®šæœˆã®ã‚µãƒãƒªãƒ¼ï¼ˆãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ï¼‰")
    st.info("CSVå–è¾¼å¾Œã€æœˆæ¬¡é›†è¨ˆã‚’å®Ÿè£…ã—ã¾ã™ã€‚")

# ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆï¼ˆãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ï¼‰
with tab4:
    st.subheader("ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆä¸€è¦§ï¼ˆãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ï¼‰")
    docs = con.execute("SELECT id,title,category,tags,ai_summary FROM documents WHERE tenant=?", [TENANT]).df()
    st.dataframe(docs, use_container_width=True)

# AIï¼ˆãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ï¼‰
with tab6:
    st.subheader("AIã‚µãƒãƒªãƒ¼ï¼ˆÎ²ï¼‰")
    st.info("OCR/AIé€£æºã¯å¾Œã§æ¥ç¶šã€‚ã¾ãšã¯CSVâ†’ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã®æµã‚Œã‚’å›ºã‚ã¾ã™ã€‚")

st.caption("Theme: ç®¡ç†ãƒ­ã‚¤ãƒ‰é¢¨ / ãƒ‡ãƒ¼ã‚¿ã¯ UTF-8 CSV ã‚’ å–è¾¼ã‚¿ãƒ–ã‹ã‚‰æŠ•å…¥")
